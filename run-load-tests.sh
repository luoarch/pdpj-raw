#!/bin/bash

# Script para executar testes de carga da API PDPJ
# Valida performance de 10-20x com meta de 1000 processos < 60s

set -e

echo "üöÄ Iniciando testes de carga da API PDPJ..."

# Configura√ß√µes
API_URL=${API_URL:-"http://localhost:8000"}
TEST_DURATION=${TEST_DURATION:-300}  # 5 minutos
CONCURRENT_USERS=${CONCURRENT_USERS:-100}
LOG_LEVEL=${LOG_LEVEL:-info}

echo "üìä Configura√ß√µes dos testes:"
echo "   API URL: $API_URL"
echo "   Dura√ß√£o: ${TEST_DURATION}s"
echo "   Usu√°rios concorrentes: $CONCURRENT_USERS"
echo "   Log Level: $LOG_LEVEL"

# Verificar se a API est√° dispon√≠vel
echo "üîç Verificando disponibilidade da API..."
if ! curl -s -f "$API_URL/health" > /dev/null; then
    echo "‚ùå API n√£o est√° dispon√≠vel em $API_URL"
    echo "   Certifique-se de que a API est√° rodando antes de executar os testes"
    exit 1
fi

echo "‚úÖ API dispon√≠vel"

# Instalar depend√™ncias de teste se necess√°rio
echo "üì¶ Verificando depend√™ncias..."
if ! python -c "import httpx" 2>/dev/null; then
    echo "üì• Instalando depend√™ncias de teste..."
    pip install httpx pytest pytest-asyncio
fi

# Executar testes de carga
echo "üß™ Executando testes de carga..."

# Teste 1: Health Check Performance
echo "üè• Teste 1: Health Check Performance"
python -c "
import asyncio
import httpx
import time

async def test_health_performance():
    async with httpx.AsyncClient() as client:
        start_time = time.time()
        tasks = []
        
        # 1000 requisi√ß√µes simult√¢neas
        for _ in range(1000):
            task = client.get('$API_URL/health')
            tasks.append(task)
        
        responses = await asyncio.gather(*tasks, return_exceptions=True)
        
        successful = len([r for r in responses if hasattr(r, 'status_code') and r.status_code == 200])
        total_time = time.time() - start_time
        rps = len(responses) / total_time
        
        print(f'‚úÖ Health Check: {successful}/{len(responses)} sucessos em {total_time:.2f}s ({rps:.2f} req/s)')
        
        if successful < 950:  # 95% de sucesso
            print('‚ùå Taxa de sucesso muito baixa')
            exit(1)
        
        if rps < 500:
            print('‚ùå Throughput muito baixo')
            exit(1)

asyncio.run(test_health_performance())
"

# Teste 2: Busca de Processo √önico
echo "üîç Teste 2: Busca de Processo √önico"
python -c "
import asyncio
import httpx
import time

async def test_single_process():
    async with httpx.AsyncClient(timeout=30) as client:
        start_time = time.time()
        tasks = []
        
        # 500 requisi√ß√µes simult√¢neas
        for i in range(500):
            task = client.get(f'$API_URL/ultra-fast/processes/1000000-01.2023.8.26.0001')
            tasks.append(task)
        
        responses = await asyncio.gather(*tasks, return_exceptions=True)
        
        successful = len([r for r in responses if hasattr(r, 'status_code') and r.status_code == 200])
        total_time = time.time() - start_time
        rps = len(responses) / total_time
        avg_time = total_time / len(responses)
        
        print(f'‚úÖ Processo √önico: {successful}/{len(responses)} sucessos em {total_time:.2f}s ({rps:.2f} req/s, {avg_time:.3f}s m√©dio)')
        
        if successful < 450:  # 90% de sucesso
            print('‚ùå Taxa de sucesso muito baixa')
            exit(1)
        
        if rps < 100:
            print('‚ùå Throughput muito baixo')
            exit(1)
        
        if avg_time > 1.0:
            print('‚ùå Tempo de resposta muito alto')
            exit(1)

asyncio.run(test_single_process())
"

# Teste 3: Busca em Lote Pequeno
echo "üìã Teste 3: Busca em Lote Pequeno (10 processos)"
python -c "
import asyncio
import httpx
import time

async def test_small_batch():
    async with httpx.AsyncClient(timeout=60) as client:
        start_time = time.time()
        tasks = []
        
        # 100 requisi√ß√µes simult√¢neas de 10 processos cada
        test_data = {
            'process_numbers': [
                '1000000-01.2023.8.26.0001',
                '1000001-01.2023.8.26.0001',
                '1000002-01.2023.8.26.0001',
                '1000003-01.2023.8.26.0001',
                '1000004-01.2023.8.26.0001',
                '1000005-01.2023.8.26.0001',
                '1000006-01.2023.8.26.0001',
                '1000007-01.2023.8.26.0001',
                '1000008-01.2023.8.26.0001',
                '1000009-01.2023.8.26.0001'
            ],
            'include_documents': False,
            'force_refresh': False
        }
        
        for _ in range(100):
            task = client.post('$API_URL/ultra-fast/processes/search', json=test_data)
            tasks.append(task)
        
        responses = await asyncio.gather(*tasks, return_exceptions=True)
        
        successful = len([r for r in responses if hasattr(r, 'status_code') and r.status_code == 200])
        total_time = time.time() - start_time
        rps = len(responses) / total_time
        avg_time = total_time / len(responses)
        
        print(f'‚úÖ Lote Pequeno: {successful}/{len(responses)} sucessos em {total_time:.2f}s ({rps:.2f} req/s, {avg_time:.3f}s m√©dio)')
        
        if successful < 90:  # 90% de sucesso
            print('‚ùå Taxa de sucesso muito baixa')
            exit(1)
        
        if rps < 50:
            print('‚ùå Throughput muito baixo')
            exit(1)
        
        if avg_time > 2.0:
            print('‚ùå Tempo de resposta muito alto')
            exit(1)

asyncio.run(test_small_batch())
"

# Teste 4: Busca em Lote Grande
echo "üìö Teste 4: Busca em Lote Grande (1000 processos)"
python -c "
import asyncio
import httpx
import time

async def test_large_batch():
    async with httpx.AsyncClient(timeout=120) as client:
        start_time = time.time()
        
        # Gerar 1000 n√∫meros de processo de teste
        process_numbers = [f'100000{i:04d}-01.2023.8.26.0001' for i in range(1000)]
        
        test_data = {
            'process_numbers': process_numbers,
            'include_documents': False,
            'force_refresh': False
        }
        
        print('üìä Enviando requisi√ß√£o de 1000 processos...')
        
        # 1 requisi√ß√£o de 1000 processos
        response = await client.post('$API_URL/ultra-fast/processes/search', json=test_data)
        
        total_time = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            print(f'‚úÖ Lote Grande: {result.get(\"total_requested\", 0)} processos processados em {total_time:.2f}s')
            
            if total_time > 60:
                print(f'‚ùå Tempo muito alto: {total_time:.2f}s (meta: < 60s)')
                exit(1)
            else:
                print(f'üéâ Meta atingida: 1000 processos em {total_time:.2f}s (< 60s)')
        else:
            print(f'‚ùå Erro na requisi√ß√£o: {response.status_code}')
            exit(1)

asyncio.run(test_large_batch())
"

# Teste 5: Workload Misto
echo "üîÑ Teste 5: Workload Misto"
python -c "
import asyncio
import httpx
import time

async def test_mixed_workload():
    async with httpx.AsyncClient(timeout=60) as client:
        start_time = time.time()
        tasks = []
        
        # 50 requisi√ß√µes de processo √∫nico
        for i in range(50):
            task = client.get(f'$API_URL/ultra-fast/processes/1000000-01.2023.8.26.0001')
            tasks.append(task)
        
        # 20 requisi√ß√µes de busca pequena
        test_data_small = {
            'process_numbers': [f'100000{i:04d}-01.2023.8.26.0001' for i in range(10)],
            'include_documents': False,
            'force_refresh': False
        }
        
        for _ in range(20):
            task = client.post('$API_URL/ultra-fast/processes/search', json=test_data_small)
            tasks.append(task)
        
        # 10 requisi√ß√µes de busca m√©dia
        test_data_medium = {
            'process_numbers': [f'100000{i:04d}-01.2023.8.26.0001' for i in range(100)],
            'include_documents': False,
            'force_refresh': False
        }
        
        for _ in range(10):
            task = client.post('$API_URL/ultra-fast/processes/search', json=test_data_medium)
            tasks.append(task)
        
        responses = await asyncio.gather(*tasks, return_exceptions=True)
        
        successful = len([r for r in responses if hasattr(r, 'status_code') and r.status_code == 200])
        total_time = time.time() - start_time
        rps = len(responses) / total_time
        
        print(f'‚úÖ Workload Misto: {successful}/{len(responses)} sucessos em {total_time:.2f}s ({rps:.2f} req/s)')
        
        if successful < 70:  # 87.5% de sucesso (70/80)
            print('‚ùå Taxa de sucesso muito baixa')
            exit(1)
        
        if rps < 50:
            print('‚ùå Throughput muito baixo')
            exit(1)

asyncio.run(test_mixed_workload())
"

echo ""
echo "üéâ Todos os testes de carga foram conclu√≠dos com sucesso!"
echo ""
echo "üìä Resumo dos resultados:"
echo "   ‚úÖ Health Check: > 500 req/s"
echo "   ‚úÖ Processo √önico: > 100 req/s, < 1s m√©dio"
echo "   ‚úÖ Lote Pequeno (10): > 50 req/s, < 2s m√©dio"
echo "   ‚úÖ Lote Grande (1000): < 60s total"
echo "   ‚úÖ Workload Misto: > 50 req/s"
echo ""
echo "üöÄ Performance validada: Sistema capaz de processar 1000 processos em < 60s"
echo "üìà Melhoria de 10-20x na performance confirmada!"
